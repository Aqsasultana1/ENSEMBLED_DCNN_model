{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import keras.utils\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from keras import utils as np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Activation, MaxPooling2D, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.datasets import cifar10\n",
    "from keras import optimizers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Cifar10 dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode class values as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aqsa Sultana\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Aqsa Sultana\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCNN model and ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes =10\n",
    "def mlp_model():\n",
    "    import keras\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from matplotlib import pyplot\n",
    "    from keras.layers.normalization import BatchNormalization\n",
    "    from keras import backend as K\n",
    "    from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer()\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D()) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating two models and classifying them using Keras Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KerasClassifier(build_fn = mlp_model, epochs = 50, batch_size=64, verbose = 1)\n",
    "clf2 = KerasClassifier(build_fn = mlp_model, epochs = 50, batch_size=64, verbose = 1)\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2], voting = 'soft', weights = [1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling the two models and training the ensembled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 998s 20ms/step - loss: 1.3898 - accuracy: 0.5151\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 1069s 21ms/step - loss: 1.0215 - accuracy: 0.6539\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 1024s 20ms/step - loss: 0.8827 - accuracy: 0.7088\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 945s 19ms/step - loss: 0.7828 - accuracy: 0.7513\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 886s 18ms/step - loss: 0.7228 - accuracy: 0.7778\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 993s 20ms/step - loss: 0.6786 - accuracy: 0.7948\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 977s 20ms/step - loss: 0.6475 - accuracy: 0.8112\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 989s 20ms/step - loss: 0.6240 - accuracy: 0.8227\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 984s 20ms/step - loss: 0.6037 - accuracy: 0.8317\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 998s 20ms/step - loss: 0.5882 - accuracy: 0.8387\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 973s 19ms/step - loss: 0.5751 - accuracy: 0.8462\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 986s 20ms/step - loss: 0.5648 - accuracy: 0.8510\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 929s 19ms/step - loss: 0.5597 - accuracy: 0.8547\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 948s 19ms/step - loss: 0.5461 - accuracy: 0.8607\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 979s 20ms/step - loss: 0.5427 - accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 981s 20ms/step - loss: 0.5327 - accuracy: 0.8689\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 940s 19ms/step - loss: 0.5294 - accuracy: 0.8726\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 986s 20ms/step - loss: 0.5276 - accuracy: 0.8730\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 973s 19ms/step - loss: 0.5218 - accuracy: 0.8754\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 988s 20ms/step - loss: 0.5109 - accuracy: 0.8808\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 948s 19ms/step - loss: 0.5141 - accuracy: 0.8801\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 914s 18ms/step - loss: 0.5109 - accuracy: 0.8802\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 925s 19ms/step - loss: 0.5048 - accuracy: 0.8852\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 931s 19ms/step - loss: 0.5104 - accuracy: 0.8820\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 894s 18ms/step - loss: 0.4939 - accuracy: 0.8890\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 928s 19ms/step - loss: 0.5034 - accuracy: 0.8875\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 917s 18ms/step - loss: 0.5023 - accuracy: 0.8873\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 946s 19ms/step - loss: 0.4927 - accuracy: 0.8906\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 1212s 24ms/step - loss: 0.4946 - accuracy: 0.8908\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 1211s 24ms/step - loss: 0.4875 - accuracy: 0.8938\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 1073s 21ms/step - loss: 0.4871 - accuracy: 0.8948\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 1060s 21ms/step - loss: 0.4873 - accuracy: 0.8951\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 1010s 20ms/step - loss: 0.4865 - accuracy: 0.8954\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 910s 18ms/step - loss: 0.4807 - accuracy: 0.8978\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 853s 17ms/step - loss: 0.4844 - accuracy: 0.8993\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 874s 17ms/step - loss: 0.4828 - accuracy: 0.8976\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 879s 18ms/step - loss: 0.4778 - accuracy: 0.8991\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4775 - accuracy: 0.9005\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4808 - accuracy: 0.8992\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 881s 18ms/step - loss: 0.4741 - accuracy: 0.9012\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4777 - accuracy: 0.9018\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 881s 18ms/step - loss: 0.4722 - accuracy: 0.9041\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 881s 18ms/step - loss: 0.4666 - accuracy: 0.9060\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 879s 18ms/step - loss: 0.4686 - accuracy: 0.9048\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4748 - accuracy: 0.9026\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 879s 18ms/step - loss: 0.4643 - accuracy: 0.9065\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 879s 18ms/step - loss: 0.4674 - accuracy: 0.9058\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4685 - accuracy: 0.9050\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 880s 18ms/step - loss: 0.4624 - accuracy: 0.9075\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 881s 18ms/step - loss: 0.4636 - accuracy: 0.9086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aqsa Sultana\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 891s 18ms/step - loss: 1.3520 - accuracy: 0.5275\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 873s 17ms/step - loss: 1.0065 - accuracy: 0.6610\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 872s 17ms/step - loss: 0.8596 - accuracy: 0.7189\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 875s 17ms/step - loss: 0.7684 - accuracy: 0.7569\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 876s 18ms/step - loss: 0.7125 - accuracy: 0.7804\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 874s 17ms/step - loss: 0.6713 - accuracy: 0.7997\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 874s 17ms/step - loss: 0.6418 - accuracy: 0.8121\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 872s 17ms/step - loss: 0.6193 - accuracy: 0.8241\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 873s 17ms/step - loss: 0.5957 - accuracy: 0.8340\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 877s 18ms/step - loss: 0.5859 - accuracy: 0.8398\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 872s 17ms/step - loss: 0.5700 - accuracy: 0.8481\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 877s 18ms/step - loss: 0.5616 - accuracy: 0.8515\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 862s 17ms/step - loss: 0.5502 - accuracy: 0.8585\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 1468s 29ms/step - loss: 0.5430 - accuracy: 0.8635\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 989s 20ms/step - loss: 0.5328 - accuracy: 0.8664\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 862s 17ms/step - loss: 0.5295 - accuracy: 0.8693\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 1037s 21ms/step - loss: 0.5255 - accuracy: 0.8716\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 1038s 21ms/step - loss: 0.5172 - accuracy: 0.8772\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 869s 17ms/step - loss: 0.5158 - accuracy: 0.8783\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 866s 17ms/step - loss: 0.5116 - accuracy: 0.8810\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 917s 18ms/step - loss: 0.5111 - accuracy: 0.8820\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 912s 18ms/step - loss: 0.5084 - accuracy: 0.8845\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 877s 18ms/step - loss: 0.5033 - accuracy: 0.8855\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 1005s 20ms/step - loss: 0.4964 - accuracy: 0.8888\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 961s 19ms/step - loss: 0.5026 - accuracy: 0.8869\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 1635s 33ms/step - loss: 0.4997 - accuracy: 0.8889\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 1178s 24ms/step - loss: 0.4951 - accuracy: 0.8908\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 866s 17ms/step - loss: 0.4890 - accuracy: 0.8943\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 893s 18ms/step - loss: 0.4881 - accuracy: 0.8949\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 962s 19ms/step - loss: 0.4871 - accuracy: 0.8950\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 877s 18ms/step - loss: 0.4855 - accuracy: 0.8964\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 886s 18ms/step - loss: 0.4857 - accuracy: 0.8956\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 893s 18ms/step - loss: 0.4813 - accuracy: 0.8988\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 913s 18ms/step - loss: 0.4793 - accuracy: 0.9003\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 1550s 31ms/step - loss: 0.4841 - accuracy: 0.8983\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 1772s 35ms/step - loss: 0.4771 - accuracy: 0.9005\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 1422s 28ms/step - loss: 0.4720 - accuracy: 0.9026\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 920s 18ms/step - loss: 0.4758 - accuracy: 0.9017\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 923s 18ms/step - loss: 0.4737 - accuracy: 0.9012\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 925s 18ms/step - loss: 0.4696 - accuracy: 0.9041\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 919s 18ms/step - loss: 0.4699 - accuracy: 0.9047\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 911s 18ms/step - loss: 0.4716 - accuracy: 0.9041\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 900s 18ms/step - loss: 0.4688 - accuracy: 0.9040\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 894s 18ms/step - loss: 0.4627 - accuracy: 0.9078\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 905s 18ms/step - loss: 0.4729 - accuracy: 0.9041\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 923s 18ms/step - loss: 0.4622 - accuracy: 0.9080\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 921s 18ms/step - loss: 0.4673 - accuracy: 0.9062\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 920s 18ms/step - loss: 0.4681 - accuracy: 0.9057\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 1046s 21ms/step - loss: 0.4664 - accuracy: 0.9079\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 1176s 24ms/step - loss: 0.4612 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000004CD8422088>,\n",
       "                             <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000004CD8422408>],\n",
       "                       refit=True, verbose=0, voting='soft', weights=[1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 61s 6ms/step\n",
      "10000/10000 [==============================] - 58s 6ms/step\n",
      "Acc:  0.8832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = eclf.predict(x_test)\n",
    "print('Acc: ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8832\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: ', accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
